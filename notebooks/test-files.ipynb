{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "744579c6-ec0c-4c73-bb38-5c99a566056f",
   "metadata": {},
   "source": [
    "# test-files.ipynb\n",
    "\n",
    "Test if we can use the LiteLLM backend for file upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6da6e33-e3dd-45d3-abad-ad48a617b1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.join(\"..\"))\n",
    "import hjson\n",
    "from llms_wrapper.llms import LLMS\n",
    "from llms_wrapper.config import update_llm_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7401b8b9-af81-4a1e-9bfa-bef00ec3ea68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'llms': [{'llm': 'openai/gpt-4o',\n",
       "   'api_key_env': 'MY_OPENAI_API_KEY',\n",
       "   'alias': 'openai/gpt-4o'},\n",
       "  {'llm': 'openai/gpt-4o-mini',\n",
       "   'api_key_env': 'MY_OPENAI_API_KEY',\n",
       "   'alias': 'openai/gpt-4o-mini'},\n",
       "  {'llm': 'gemini/gemini-2.0-flash-exp',\n",
       "   'api_key_env': 'MY_GEMINI_API_KEY',\n",
       "   'alias': 'gemini/gemini-2.0-flash-exp'},\n",
       "  {'llm': 'gemini/gemini-1.5-flash',\n",
       "   'api_key_env': 'MY_GEMINI_API_KEY',\n",
       "   'alias': 'gemini/gemini-1.5-flash'},\n",
       "  {'llm': 'gemini/gemini-1.5-pro',\n",
       "   'api_key_env': 'MY_GEMINI_API_KEY',\n",
       "   'alias': 'gemini/gemini-1.5-pro'},\n",
       "  {'llm': 'anthropic/claude-3-5-sonnet-20240620',\n",
       "   'api_key_env': 'MY_ANTHROPIC_API_KEY',\n",
       "   'alias': 'anthropic/claude-3-5-sonnet-20240620'},\n",
       "  {'llm': 'anthropic/claude-3-opus-20240229',\n",
       "   'api_key_env': 'MY_ANTHROPIC_API_KEY',\n",
       "   'alias': 'anthropic/claude-3-opus-20240229'},\n",
       "  {'llm': 'mistral/mistral-large-latest',\n",
       "   'api_key_env': 'MY_MISTRAL_API_KEY',\n",
       "   'alias': 'mistral/mistral-large-latest'},\n",
       "  {'llm': 'xai/grok-beta',\n",
       "   'api_key_env': 'MY_XAI_API_KEY',\n",
       "   'alias': 'xai/grok-beta'},\n",
       "  {'llm': 'groq/llama3-70b-8192',\n",
       "   'api_key_env': 'MY_GROQ_API_KEY',\n",
       "   'alias': 'groq/llama3-70b-8192'},\n",
       "  {'llm': 'groq/llama-3.3-70b-versatile',\n",
       "   'api_key_env': 'MY_GROQ_API_KEY',\n",
       "   'alias': 'groq/llama-3.3-70b-versatile'},\n",
       "  {'llm': 'deepseek/deepseek-chat',\n",
       "   'api_key_env': 'MY_DEEPSEEK_API_KEY',\n",
       "   'alias': 'deepseek/deepseek-chat'}],\n",
       " 'providers': {'openai': {'api_key_env': 'MY_OPENAI_API_KEY'},\n",
       "  'gemini': {'api_key_env': 'MY_GEMINI_API_KEY'},\n",
       "  'anthropic': {'api_key_env': 'MY_ANTHROPIC_API_KEY'},\n",
       "  'mistral': {'api_key_env': 'MY_MISTRAL_API_KEY'},\n",
       "  'xai': {'api_key_env': 'MY_XAI_API_KEY'},\n",
       "  'groq': {'api_key_env': 'MY_GROQ_API_KEY'},\n",
       "  'deepseek': {'api_key_env': 'MY_DEEPSEEK_API_KEY'}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = dict(\n",
    "    llms=[\n",
    "        # OpenAI\n",
    "        # https://platform.openai.com/docs/models\n",
    "        dict(llm=\"openai/gpt-4o\"),\n",
    "        dict(llm=\"openai/gpt-4o-mini\"),\n",
    "        # dict(llm=\"openai/o1\"),        # restricted\n",
    "        # dict(llm=\"openai/o1-mini\"),   # restricted\n",
    "        # Google Gemini\n",
    "        # https://ai.google.dev/gemini-api/docs/models/gemini\n",
    "        dict(llm=\"gemini/gemini-2.0-flash-exp\"),\n",
    "        dict(llm=\"gemini/gemini-1.5-flash\"),\n",
    "        dict(llm=\"gemini/gemini-1.5-pro\"),\n",
    "        # Anthropic\n",
    "        # https://docs.anthropic.com/en/docs/about-claude/models\n",
    "        dict(llm=\"anthropic/claude-3-5-sonnet-20240620\"),\n",
    "        dict(llm=\"anthropic/claude-3-opus-20240229\"),\n",
    "        # Mistral\n",
    "        # https://docs.mistral.ai/getting-started/models/models_overview/\n",
    "        dict(llm=\"mistral/mistral-large-latest\"),\n",
    "        # XAI\n",
    "        # dict(llm=\"xai/grok-2\"),     # not mapped by litellm yet?\n",
    "        dict(llm=\"xai/grok-beta\"),\n",
    "        # Groq\n",
    "        # https://console.groq.com/docs/models\n",
    "        dict(llm=\"groq/llama3-70b-8192\"),\n",
    "        dict(llm=\"groq/llama-3.3-70b-versatile\"),\n",
    "        # Deepseek\n",
    "        # https://api-docs.deepseek.com/quick_start/pricing\n",
    "        dict(llm=\"deepseek/deepseek-chat\"),\n",
    "    ],\n",
    "    providers = dict(\n",
    "        openai = dict(api_key_env=\"MY_OPENAI_API_KEY\"),\n",
    "        gemini = dict(api_key_env=\"MY_GEMINI_API_KEY\"),\n",
    "        anthropic = dict(api_key_env=\"MY_ANTHROPIC_API_KEY\"),\n",
    "        mistral = dict(api_key_env=\"MY_MISTRAL_API_KEY\"),\n",
    "        xai = dict(api_key_env=\"MY_XAI_API_KEY\"),    \n",
    "        groq = dict(api_key_env=\"MY_GROQ_API_KEY\"),\n",
    "        deepseek = dict(api_key_env=\"MY_DEEPSEEK_API_KEY\"),\n",
    "    )\n",
    ")\n",
    "update_llm_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a2eb12c-7219-49ee-8f47-e3e87b719795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['openai/gpt-4o',\n",
       " 'openai/gpt-4o-mini',\n",
       " 'gemini/gemini-2.0-flash-exp',\n",
       " 'gemini/gemini-1.5-flash',\n",
       " 'gemini/gemini-1.5-pro',\n",
       " 'anthropic/claude-3-5-sonnet-20240620',\n",
       " 'anthropic/claude-3-opus-20240229',\n",
       " 'mistral/mistral-large-latest',\n",
       " 'xai/grok-beta',\n",
       " 'groq/llama3-70b-8192',\n",
       " 'groq/llama-3.3-70b-versatile',\n",
       " 'deepseek/deepseek-chat']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llms = LLMS(config)\n",
    "llms.list_aliases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc424b7d-1a62-4ea6-8bad-5df5b32e4588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "with open(\"test1.pdf\", \"rb\") as infp:\n",
    "    file_data = infp.read()\n",
    "encoded_file = base64.b64encode(file_data).decode(\"utf-8\")\n",
    "messages3 = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"You are a very professional document summarization specialist. Please summarize the given document.\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": f\"data:application/pdf;base64,{encoded_file}\", # ðŸ‘ˆ PDF\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4034a9f7-414c-4ea5-b47f-a4d3490ccf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "with open(\"test1.md\", \"rb\") as infp:\n",
    "    md_file = infp.read()\n",
    "encoded_md_file = base64.b64encode(file_data).decode(\"utf-8\")\n",
    "messages4 = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"You are a very professional document summarization specialist. Please summarize the given document.\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": f\"data:text/md,{md_file}\", \n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a26b470-ba58-4b86-ad40-57445d06d7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/johann/software/miniconda3/envs/llms_wrapper/lib/python3.11/site-packages/litellm/litellm_core_utils/prompt_templates/factory.py\", line 704, in convert_to_anthropic_image_obj\n",
      "    media_type, base64_data = openai_image_url.split(\"data:\")[1].split(\";base64,\")\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'error': 'litellm.APIConnectionError: Image url not in expected format. Example Expected input - \"image_url\": \"data:image/jpeg;base64,{base64_image}\". Supported formats - [\\'image/jpeg\\', \\'image/png\\', \\'image/gif\\', \\'image/webp\\'].\\nTraceback (most recent call last):\\n  File \"/home/johann/software/miniconda3/envs/llms_wrapper/lib/python3.11/site-packages/litellm/litellm_core_utils/prompt_templates/factory.py\", line 704, in convert_to_anthropic_image_obj\\n    media_type, base64_data = openai_image_url.split(\"data:\")[1].split(\";base64,\")\\n    ^^^^^^^^^^^^^^^^^^^^^^^\\nValueError: not enough values to unpack (expected 2, got 1)\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/home/johann/software/miniconda3/envs/llms_wrapper/lib/python3.11/site-packages/litellm/main.py\", line 2336, in completion\\n    response = vertex_chat_completion.completion(  # type: ignore\\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/johann/software/miniconda3/envs/llms_wrapper/lib/python3.11/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py\", line 1232, in completion\\n    data = sync_transform_request_body(**transform_request_params)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/johann/software/miniconda3/envs/llms_wrapper/lib/python3.11/site-packages/litellm/llms/vertex_ai/gemini/transformation.py\", line 379, in sync_transform_request_body\\n    return _transform_request_body(\\n           ^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/johann/software/miniconda3/envs/llms_wrapper/lib/python3.11/site-packages/litellm/llms/vertex_ai/gemini/transformation.py\", line 342, in _transform_request_body\\n    raise e\\n  File \"/home/johann/software/miniconda3/envs/llms_wrapper/lib/python3.11/site-packages/litellm/llms/vertex_ai/gemini/transformation.py\", line 307, in _transform_request_body\\n    content = litellm.GoogleAIStudioGeminiConfig()._transform_messages(\\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/johann/software/miniconda3/envs/llms_wrapper/lib/python3.11/site-packages/litellm/llms/gemini/chat/transformation.py\", line 122, in _transform_messages\\n    image_obj = convert_to_anthropic_image_obj(_image_url)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/johann/software/miniconda3/envs/llms_wrapper/lib/python3.11/site-packages/litellm/litellm_core_utils/prompt_templates/factory.py\", line 716, in convert_to_anthropic_image_obj\\n    raise Exception(\\nException: Image url not in expected format. Example Expected input - \"image_url\": \"data:image/jpeg;base64,{base64_image}\". Supported formats - [\\'image/jpeg\\', \\'image/png\\', \\'image/gif\\', \\'image/webp\\'].\\n in /home/johann/software/miniconda3/envs/llms_wrapper/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:2186 exception_type',\n",
       " 'answer': '',\n",
       " 'ok': False}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gemini is the only one that supports file type pdf, \n",
    "# for other types see: https://ai.google.dev/gemini-api/docs/document-processing?lang=python#technical-details\n",
    "ret = llms.query(\"gemini/gemini-2.0-flash-exp\", messages=messages4)\n",
    "# ret = llms.query(\"openai/gpt-4o\", messages=messages3)  # only works with images\n",
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f50ecff6-28b6-487d-b106-887aaa2c4f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: openai/gpt-4o\n",
      "  Answer: Albert\n",
      "Model: openai/gpt-4o-mini\n",
      "  Answer: Albert\n",
      "Model: gemini/gemini-2.0-flash-exp\n",
      "  Answer: Albert\n",
      "\n",
      "Model: gemini/gemini-1.5-flash\n",
      "  Answer: Albert\n",
      "\n",
      "Model: gemini/gemini-1.5-pro\n",
      "  Answer: Albert\n",
      "\n",
      "Model: anthropic/claude-3-5-sonnet-20240620\n",
      "  Answer: Albert\n",
      "Model: anthropic/claude-3-opus-20240229\n",
      "  Answer: Albert\n",
      "Model: mistral/mistral-large-latest\n",
      "  Answer: Albert\n",
      "Model: xai/grok-beta\n",
      "  Answer: Albert\n",
      "Model: groq/llama3-70b-8192\n",
      "  Answer: Albert\n",
      "Model: groq/llama-3.3-70b-versatile\n",
      "  Answer: Albert\n",
      "Model: deepseek/deepseek-chat\n",
      "  Answer: Albert\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for llmalias in llms.list_aliases():\n",
    "    print(\"Model:\", llmalias)\n",
    "    cinfo = {}\n",
    "    ret = llms.query(\n",
    "        llmalias, \n",
    "        messages=messages, \n",
    "        return_cost=True,\n",
    "        debug=False,\n",
    "    )\n",
    "    answer = ret[\"answer\"]\n",
    "    error = ret[\"error\"]\n",
    "    if error:\n",
    "        print(\"  ERROR:\", error)\n",
    "    else:\n",
    "        print(\"  Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbb08eba-fef2-449e-b9b4-efa69fe1ca4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLM(openai/gpt-4o)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test using the LLM object\n",
    "llm1 = llms[\"openai/gpt-4o\"]\n",
    "llm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4240545-16a6-432a-ba66-c578e34f2c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elapsed_time': 0.7788379192352295,\n",
       " 'cost': 0.000105,\n",
       " 'n_completion_tokens': 2,\n",
       " 'n_prompt_tokens': 34,\n",
       " 'n_total_tokens': 36,\n",
       " 'answer': 'Albert',\n",
       " 'error': '',\n",
       " 'ok': True}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret = llm1.query(messages=messages, \n",
    "        return_cost=True,\n",
    "        debug=False,)\n",
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50489a92-0520-4ae9-ad74-7c5f27c6c25e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms_wrapper",
   "language": "python",
   "name": "llms_wrapper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
