{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "744579c6-ec0c-4c73-bb38-5c99a566056f",
   "metadata": {},
   "source": [
    "# dev-tooling.ipynb\n",
    "\n",
    "Develop the API code to support tooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75314c45",
   "metadata": {},
   "source": [
    "## LiteLLM Original Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48f923b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.66.0\n",
      "\n",
      "First LLM Response:\n",
      " ModelResponse(id='chatcmpl-BPYZS5X7TqoZBFq0eChv0MZ7IJcZ5', created=1745430790, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_a6889ffe71', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{\"location\": \"San Francisco, CA\"}', name='get_current_weather'), id='call_CM8YvUssPu0esXDocqERKxoV', type='function'), ChatCompletionMessageToolCall(function=Function(arguments='{\"location\": \"Tokyo, Japan\"}', name='get_current_weather'), id='call_ObiKjcD4OkO4hapX5JFtkWom', type='function'), ChatCompletionMessageToolCall(function=Function(arguments='{\"location\": \"Paris, France\"}', name='get_current_weather'), id='call_70kJUfm5HTM0S1z9S2oIuheG', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[]))], usage=Usage(completion_tokens=69, prompt_tokens=85, total_tokens=154, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')\n",
      "\n",
      "Length of tool calls 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johann/software/anaconda/envs/llms_wrapper/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `ChatCompletionMessageToolCall` - serialized value may not be as expected [input_value={'function': {'arguments'...oV', 'type': 'function'}, input_type=dict])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ChatCompletionMessageToolCall` - serialized value may not be as expected [input_value={'function': {'arguments'...om', 'type': 'function'}, input_type=dict])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ChatCompletionMessageToolCall` - serialized value may not be as expected [input_value={'function': {'arguments'...eG', 'type': 'function'}, input_type=dict])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Second LLM response:\n",
      " ModelResponse(id='chatcmpl-BPYZTITWPO9sSPdsbCHlITLOUp7q4', created=1745430791, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_90122d973c', choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Here's the current weather in the following cities:\\n\\n- **San Francisco, CA**: The temperature is 72°F.\\n- **Tokyo, Japan**: The temperature is 10°C.\\n- **Paris, France**: The temperature is 22°C.\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]))], usage=Usage(completion_tokens=53, prompt_tokens=158, total_tokens=211, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelResponse(id='chatcmpl-BPYZTITWPO9sSPdsbCHlITLOUp7q4', created=1745430791, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_90122d973c', choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Here's the current weather in the following cities:\\n\\n- **San Francisco, CA**: The temperature is 72°F.\\n- **Tokyo, Japan**: The temperature is 10°C.\\n- **Paris, France**: The temperature is 22°C.\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]))], usage=Usage(completion_tokens=53, prompt_tokens=158, total_tokens=211, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import litellm\n",
    "import importlib\n",
    "print(importlib.metadata.version(\"litellm\"))\n",
    "import json\n",
    "# set openai api key\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = os.environ['MY_OPENAI_API_KEY']\n",
    "MODEL = \"openai/gpt-4o\"\n",
    "\n",
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    if \"tokyo\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": \"celsius\"})\n",
    "    elif \"san francisco\" in location.lower():\n",
    "        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"})\n",
    "    elif \"paris\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": \"celsius\"})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n",
    "\n",
    "\n",
    "def test_parallel_function_call():\n",
    "    try:\n",
    "        # Step 1: send the conversation and available functions to the model\n",
    "        messages = [{\"role\": \"user\", \"content\": \"What's the weather like in San Francisco, Tokyo, and Paris?\"}]\n",
    "        tools = [\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"get_current_weather\",\n",
    "                    \"description\": \"Get the current weather in a given location\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"location\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                            },\n",
    "                            \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                        },\n",
    "                        \"required\": [\"location\"],\n",
    "                    },\n",
    "                },\n",
    "            }\n",
    "        ]\n",
    "        response = litellm.completion(\n",
    "            model=MODEL,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    "        )\n",
    "        print(\"\\nFirst LLM Response:\\n\", response)\n",
    "        response_message = response.choices[0].message\n",
    "        tool_calls = response_message.tool_calls\n",
    "\n",
    "        print(\"\\nLength of tool calls\", len(tool_calls))\n",
    "\n",
    "        # Step 2: check if the model wanted to call a function\n",
    "        if tool_calls:\n",
    "            # Step 3: call the function\n",
    "            # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "            available_functions = {\n",
    "                \"get_current_weather\": get_current_weather,\n",
    "            }  # only one function in this example, but you can have multiple\n",
    "            messages.append(response_message)  # extend conversation with assistant's reply\n",
    "\n",
    "            # Step 4: send the info for each function call and function response to the model\n",
    "            for tool_call in tool_calls:\n",
    "                function_name = tool_call.function.name\n",
    "                function_to_call = available_functions[function_name]\n",
    "                function_args = json.loads(tool_call.function.arguments)\n",
    "                function_response = function_to_call(\n",
    "                    location=function_args.get(\"location\"),\n",
    "                    unit=function_args.get(\"unit\"),\n",
    "                )\n",
    "                messages.append(\n",
    "                    {\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"role\": \"tool\",\n",
    "                        \"name\": function_name,\n",
    "                        \"content\": function_response,\n",
    "                    }\n",
    "                )  # extend conversation with function response\n",
    "            second_response = litellm.completion(\n",
    "                model=MODEL,\n",
    "                messages=messages,\n",
    "            )  # get a new response from the model where it can see the function response\n",
    "            print(\"\\nSecond LLM response:\\n\", second_response)\n",
    "            return second_response\n",
    "    except Exception as e:\n",
    "      print(f\"Error occurred: {e}\")\n",
    "\n",
    "test_ret1 = test_parallel_function_call()\n",
    "test_ret1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eb18b2",
   "metadata": {},
   "source": [
    "## Own Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6da6e33-e3dd-45d3-abad-ad48a617b1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from typing import Optional, List, Dict\n",
    "import docstring_parser\n",
    "sys.path.append(os.path.join(\"..\"))\n",
    "from llms_wrapper.llms import LLMS, toolnames2funcs, get_func_by_name\n",
    "from llms_wrapper.config import update_llm_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7401b8b9-af81-4a1e-9bfa-bef00ec3ea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    llms=[\n",
    "        # OpenAI\n",
    "        # https://platform.openai.com/docs/models\n",
    "        dict(llm=\"openai/gpt-4o\"),\n",
    "        dict(llm=\"openai/gpt-4o-mini\"),\n",
    "        # dict(llm=\"openai/o1\"),        # restricted\n",
    "        # dict(llm=\"openai/o1-mini\"),   # restricted\n",
    "        # Google Gemini\n",
    "        # https://ai.google.dev/gemini-api/docs/models/gemini\n",
    "        dict(llm=\"gemini/gemini-2.0-flash-exp\"),\n",
    "        dict(llm=\"gemini/gemini-1.5-flash\"),\n",
    "        dict(llm=\"gemini/gemini-1.5-pro\"),\n",
    "        # Anthropic\n",
    "        # https://docs.anthropic.com/en/docs/about-claude/models\n",
    "        dict(llm=\"anthropic/claude-3-5-sonnet-20240620\"),\n",
    "        dict(llm=\"anthropic/claude-3-opus-20240229\"),\n",
    "        # Mistral\n",
    "        # https://docs.mistral.ai/getting-started/models/models_overview/\n",
    "        dict(llm=\"mistral/mistral-large-latest\"),\n",
    "        # XAI\n",
    "        # dict(llm=\"xai/grok-2\"),     # not mapped by litellm yet?\n",
    "        dict(llm=\"xai/grok-beta\"),\n",
    "        # Groq\n",
    "        # https://console.groq.com/docs/models\n",
    "        dict(llm=\"groq/llama3-70b-8192\"),\n",
    "        dict(llm=\"groq/llama-3.3-70b-versatile\"),\n",
    "        # Deepseek\n",
    "        # https://api-docs.deepseek.com/quick_start/pricing\n",
    "        dict(llm=\"deepseek/deepseek-chat\"),\n",
    "    ],\n",
    "    providers = dict(\n",
    "        openai = dict(api_key_env=\"MY_OPENAI_API_KEY\"),\n",
    "        gemini = dict(api_key_env=\"MY_GEMINI_API_KEY\"),\n",
    "        anthropic = dict(api_key_env=\"MY_ANTHROPIC_API_KEY\"),\n",
    "        mistral = dict(api_key_env=\"MY_MISTRAL_API_KEY\"),\n",
    "        xai = dict(api_key_env=\"MY_XAI_API_KEY\"),    \n",
    "        groq = dict(api_key_env=\"MY_GROQ_API_KEY\"),\n",
    "        deepseek = dict(api_key_env=\"MY_DEEPSEEK_API_KEY\"),\n",
    "    )\n",
    ")\n",
    "config = update_llm_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "078083b6-dcf4-4d7e-9950-36ffb058732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llms = LLMS(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a2eb12c-7219-49ee-8f47-e3e87b719795",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['openai/gpt-4o',\n",
       " 'openai/gpt-4o-mini',\n",
       " 'gemini/gemini-2.0-flash-exp',\n",
       " 'gemini/gemini-1.5-flash',\n",
       " 'gemini/gemini-1.5-pro',\n",
       " 'anthropic/claude-3-5-sonnet-20240620',\n",
       " 'anthropic/claude-3-opus-20240229',\n",
       " 'mistral/mistral-large-latest',\n",
       " 'xai/grok-beta',\n",
       " 'groq/llama3-70b-8192',\n",
       " 'groq/llama-3.3-70b-versatile',\n",
       " 'deepseek/deepseek-chat']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llms.list_aliases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c7f6986-347b-4e50-94bb-31272e798130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_names(where_clause: str) -> List[str]: \n",
    "    \"\"\"\n",
    "    Query the customer database and return a list of matching names. \n",
    "\n",
    "    This function queries the customer database using the conditions in the where clause and returns\n",
    "    a list of matching customers. The where clause may use the DB fields \"city\", \"company_name\",\n",
    "    \"country\" and \"since_date\" to limit the returned customer list. The where clause can also \n",
    "    be followed by a limit clause to limit the number of returned names. \n",
    "\n",
    "    :param where_clause: the string containing the where and optionally limit clauses in SQL query format\n",
    "    :type where_clause: string\n",
    "    :return: a list of matching customer names\n",
    "    :rtype: array\n",
    "    \"\"\"\n",
    "    return [\"Monica Schmidt\", \"Harald Mueller\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8365cc3a",
   "metadata": {},
   "source": [
    "## Tooling description creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33420075",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "def testfunc1(parm1: str, parm2: Dict[str, List[int]], parm3: bool = True, parm4: List = None) -> list[dict[str, str]]:\n",
    "    \"\"\" \n",
    "    Short description of the function.\n",
    "\n",
    "    Here is a longer description of the function. It can be multiple lines long and\n",
    "    can contain any information that is relevant to the function.\n",
    "    \n",
    "\n",
    "    :param parm1: the first parameter\n",
    "    :type parm1: str\n",
    "    :param parm2: the second parameter\n",
    "    :param parm3: the third parameter\n",
    "    :type parm3: boolean\n",
    "    :param parm4: the fourth parameter\n",
    "    :type parm4: {\"type\": \"array!\", \"items\": {\"type\": \"object\", \"properties\": {\"name\": {\"type\": \"string\"}, \"city\": {\"type\": \"string\"}}}}\n",
    "    :return: A list of person information, each having a name and city and optional other fields\n",
    "    :rtype: list[dict[str, str]]\n",
    "    \"\"\"\n",
    "    return [{\"name\": \"Monica Schmidt\", \"city\": \"Berlin\"}, {\"name\": \"Harald Mueller\", \"city\": \"Munich\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "082bfc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FullArgSpec(args=['parm1', 'parm2', 'parm3', 'parm4'], varargs=None, varkw=None, defaults=(True, None), kwonlyargs=[], kwonlydefaults=None, annotations={'return': list[dict[str, str]], 'parm1': <class 'str'>, 'parm2': typing.Dict[str, typing.List[int]], 'parm3': <class 'bool'>, 'parm4': typing.List})\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "argspec1 = inspect.getfullargspec(testfunc1)\n",
    "print(argspec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "148bf77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parm1 <class 'str'>\n",
      "parm2 typing.Dict[str, typing.List[int]]\n",
      "parm3 <class 'bool'>\n",
      "parm4 typing.List\n"
     ]
    }
   ],
   "source": [
    "for pname in argspec1.args:\n",
    "    print(pname, argspec1.annotations.get(pname, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2acd69b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parm2a = argspec1.annotations.get(\"parm2\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa117542",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'dict' has no attribute '_args__'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mparm2a\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_args__\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/johann/software/anaconda/envs/llms_wrapper/lib/python3.11/typing.py:1317\u001b[39m, in \u001b[36m_BaseGenericAlias.__getattr__\u001b[39m\u001b[34m(self, attr)\u001b[39m\n\u001b[32m   1314\u001b[39m \u001b[38;5;66;03m# We are careful for copy and pickle.\u001b[39;00m\n\u001b[32m   1315\u001b[39m \u001b[38;5;66;03m# Also for simplicity we don't relay any dunder names\u001b[39;00m\n\u001b[32m   1316\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m__origin__\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_dunder(attr):\n\u001b[32m-> \u001b[39m\u001b[32m1317\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.__origin__, attr)\n\u001b[32m   1318\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(attr)\n",
      "\u001b[31mAttributeError\u001b[39m: type object 'dict' has no attribute '_args__'"
     ]
    }
   ],
   "source": [
    "parm2a._args__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e5677ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(parm1: str, parm2: Dict[str, List[int]], parm3: bool = True, parm4: List = None) -> list[dict[str, str]]\n",
      "parm1: type=<class 'str'>, default=<class 'inspect._empty'>\n",
      "parm2: type=typing.Dict[str, typing.List[int]], default=<class 'inspect._empty'>\n",
      "parm3: type=<class 'bool'>, default=True\n",
      "parm4: type=typing.List, default=None\n",
      "list[dict[str, str]]\n",
      "list\n",
      "(dict[str, str],)\n"
     ]
    }
   ],
   "source": [
    "argspec2 = inspect.signature(testfunc1)\n",
    "print(argspec2)\n",
    "for pname, pval in argspec2.parameters.items():\n",
    "    print(f\"{pname}: type={pval.annotation}, default={pval.default}\")\n",
    "print(argspec2.return_annotation)\n",
    "print(argspec2.return_annotation.__name__)\n",
    "print(argspec2.return_annotation.__args__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "785ca2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parm2b = argspec2.parameters.get(\"parm2\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10fc7306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(str, typing.List[int])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parm2b.annotation.__args__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "748a64c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parm2: Dict[str, List[int]]\n"
     ]
    }
   ],
   "source": [
    "# function which recursively inspects a python type annotation and prints either an integral type or recursively a parametrized type and its parameters\n",
    "def print_annotation(annotation):\n",
    "    if hasattr(annotation, '__name__'):\n",
    "        print(annotation.__name__)\n",
    "    elif hasattr(annotation, '__args__'):\n",
    "        print(\"DEBUG: have args: \", annotation.__args__)\n",
    "        print(annotation.__origin__.__name__, end='(')\n",
    "        for arg in annotation.__args__:\n",
    "            print_annotation(arg)\n",
    "            print(', ', end='')\n",
    "        print(')')\n",
    "    else:\n",
    "        print(annotation)\n",
    "print_annotation(parm2b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1818efa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = docstring_parser.parse(testfunc1.__doc__)\n",
    "docret = doc.returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7a38201c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'args': ['return'],\n",
       " 'description': 'A list of person information, each having a name and city and optional other fields',\n",
       " 'type_name': 'list[dict[str, str]]',\n",
       " 'is_generator': False,\n",
       " 'return_name': None}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docret.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "36675611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create a single parameter description schema from the parameter name, python type and description\n",
    "import typing\n",
    "from typing import Optional, List, Dict, Union\n",
    "import docstring_parser\n",
    "from typing import get_origin, get_args\n",
    "import json\n",
    "import sys\n",
    "\n",
    "def ptype2schema(py_type):\n",
    "    # Handle bare None\n",
    "    if py_type is type(None):\n",
    "        return {\"type\": \"null\"}\n",
    "\n",
    "    origin = get_origin(py_type)\n",
    "    args = get_args(py_type)\n",
    "\n",
    "    if origin is None:\n",
    "        # Base types\n",
    "        if py_type is str:\n",
    "            return {\"type\": \"string\"}\n",
    "        elif py_type is int:\n",
    "            return {\"type\": \"integer\"}\n",
    "        elif py_type is float:\n",
    "            return {\"type\": \"number\"}\n",
    "        elif py_type is bool:\n",
    "            return {\"type\": \"boolean\"}\n",
    "        elif py_type is type(None):\n",
    "            return {\"type\": \"null\"}\n",
    "        else:\n",
    "            return {\"type\": \"string\"}  # Fallback\n",
    "\n",
    "    elif origin is list or origin is typing.List:\n",
    "        item_type = ptype2schema(args[0]) if args else {\"type\": \"string\"}\n",
    "        return {\"type\": \"array\", \"items\": item_type}\n",
    "\n",
    "    elif origin is dict or origin is typing.Dict:\n",
    "        key_type, val_type = args if args else (str, str)\n",
    "        # JSON Schema requires string keys\n",
    "        if key_type != str:\n",
    "            raise ValueError(\"JSON object keys must be strings\")\n",
    "        return {\"type\": \"object\", \"additionalProperties\": ptype2schema(val_type)}\n",
    "\n",
    "    elif origin is typing.Union:\n",
    "        # Flatten nested Union\n",
    "        flat_args = []\n",
    "        for arg in args:\n",
    "            if get_origin(arg) is typing.Union:\n",
    "                flat_args.extend(get_args(arg))\n",
    "            else:\n",
    "                flat_args.append(arg)\n",
    "\n",
    "        schemas = [ptype2schema(a) for a in flat_args]\n",
    "        return {\"anyOf\": schemas}\n",
    "\n",
    "    elif origin is typing.Literal:\n",
    "        return {\"enum\": list(args)}\n",
    "\n",
    "    else:\n",
    "        return {\"type\": \"string\"}  # fallback for unsupported/unknown\n",
    "    \n",
    "def function2schema(func, include_return_type=True):\n",
    "    doc = docstring_parser.parse(func.__doc__)\n",
    "    desc = doc.short_description + \"\\n\\n\" + doc.long_description if doc.long_description else doc.short_description\n",
    "    if not desc:\n",
    "        raise ValueError(\"Function docstring is empty\")\n",
    "    argdescs = {arg.arg_name: arg.description for arg in doc.params}    \n",
    "    argtypes = {}\n",
    "    for arg in doc.params:\n",
    "        argtype = arg.type_name\n",
    "        print(f\"Debug: argtype for {arg.arg_name}: {argtype}, type: {type(argtype)}\")\n",
    "        # if the argtype is not specified, skip, we will use the argument type\n",
    "        if argtype is None:\n",
    "            print(f\"Debug: argtype for {arg.arg_name} is None, skipping\")\n",
    "            continue\n",
    "        # if the argtype starts with a brace, we assume it is already specified as a JSON schema\n",
    "        if argtype.startswith(\"{\"):\n",
    "            print(f\"Debug: argtype for {arg.arg_name} is a JSON schema ({argtype}), using as is\")                        \n",
    "            argtypes[arg.arg_name] = json.loads(argtype)\n",
    "        else:\n",
    "            # otherwise, we assume it is a python type            \n",
    "            argtypes[arg.arg_name] = ptype2schema(argtype)\n",
    "            print(f\"Debug: argtype for {arg.arg_name} is a python type, converted to JSON schema {argtypes[arg.arg_name]}\")\n",
    "    print(f\"Debug: argtypes: {argtypes}\")\n",
    "    retdesc = doc.returns.description if doc.returns else \"\"\n",
    "    if not retdesc:\n",
    "        raise ValueError(\"Function return type is not specified in docstring\")\n",
    "    retschema = ptype2schema(func.__annotations__.get(\"return\", None))\n",
    "    desc = desc + \"\\n\\n\" + \"The function returns: \" + str(retdesc)\n",
    "    if include_return_type:\n",
    "        desc = desc + \"\\n\\n\" + \"The return type is: \" + str(retschema)\n",
    "    sig = inspect.signature(func)\n",
    "    parameters = sig.parameters\n",
    "\n",
    "    props = {}\n",
    "    required = []\n",
    "\n",
    "    for name, param in parameters.items():\n",
    "        if name == 'self':\n",
    "            continue\n",
    "\n",
    "        if name in argtypes:\n",
    "            print(f\"Debug: argtype for {name} is in argtypes, using as is: {argtypes[name]}\")\n",
    "            schema = argtypes[name]\n",
    "        else:\n",
    "            print(f\"Debug: argtype for {name} is not in argtypes, using function signature {name}: {param}\")\n",
    "            # Use the type annotation if available, otherwise default to string\n",
    "            ptype = param.annotation if param.annotation != inspect.Parameter.empty else str\n",
    "            schema = ptype2schema(ptype)\n",
    "        schema[\"description\"] = argdescs.get(name, \"\")\n",
    "\n",
    "        if param.default != inspect.Parameter.empty:\n",
    "            schema[\"default\"] = param.default\n",
    "        else:\n",
    "            required.append(name)\n",
    "\n",
    "        props[name] = schema\n",
    "\n",
    "    return {\n",
    "        \"name\": func.__name__,\n",
    "        \"description\": desc,\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": props,\n",
    "            \"required\": required\n",
    "        }\n",
    "    }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2d06bc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parm2: Dict[str, List[int]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'type': 'object',\n",
       " 'additionalProperties': {'type': 'array', 'items': {'type': 'integer'}}}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(parm2b)\n",
    "ptype2schema(parm2b.annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1370d83",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'function2schema' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mfunction2schema\u001b[49m(testfunc1)\n",
      "\u001b[31mNameError\u001b[39m: name 'function2schema' is not defined"
     ]
    }
   ],
   "source": [
    "function2schema(testfunc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4722fb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monica Schmidt', 'Harald Mueller']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmpfunc(\"city='Berlin' and company_name='Acme Corp' and since_date='2023-01-01' and limit=10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b49ca6c6-e5ef-4a92-81b2-307c4c01143a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'query_names',\n",
       "   'description': 'Query the customer database and return a list of matching names. \\n\\nThis function queries the customer database using the conditions in the where clause and returns\\na list of matching customers. The where clause may use the DB fields \"city\", \"company_name\",\\n\"country\" and \"since_date\" to limit the returned customer list. The where clause can also \\nbe followed by a limit clause to limit the number of returned names.',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'where_clause': {'type': 'string',\n",
       "      'description': 'the string containing the where and optionally limit clauses in SQL query format'}},\n",
       "    'required': ['where_clause']}}}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools=llms.make_tooling(query_names)\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2b274f9-a160-4074-a022-3d377fdc82fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llms.supports_function_calling(\"openai/gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07928eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llms.supports_function_calling(\"openai/gpt-4o\", parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "930d815e-d4fc-4a2e-aba0-4d4593900f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'Give me the names of customers in New York which have been customers since 2023 or longer',\n",
       "  'role': 'user'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = llms.make_messages(\"Give me the names of customers in New York which have been customers since 2023 or longer\")\n",
    "msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "338e3b72-2ccc-47a0-9248-c422a232fdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johann/software/anaconda/envs/llms_wrapper/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `ChatCompletionMessageToolCall` - serialized value may not be as expected [input_value={'function': {'arguments'...xq', 'type': 'function'}, input_type=dict])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('The customers in New York who have been customers since 2023 or longer are:\\n\\n- Monica Schmidt\\n- Harald Mueller',\n",
       " '')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret = llms.query(\"openai/gpt-4o\", messages=msgs, tools=tools, return_cost=True)\n",
    "ret[\"answer\"], ret[\"error\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fd40ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elapsed_time': 1.8553009033203125,\n",
       " 'cost': 0.0015425,\n",
       " 'n_completion_tokens': 63,\n",
       " 'n_prompt_tokens': 365,\n",
       " 'n_total_tokens': 428,\n",
       " 'finish_reason': 'stop',\n",
       " 'answer': 'Here are the names of customers in New York who have been customers since 2023 or longer:\\n\\n1. Monica Schmidt\\n2. Harald Mueller',\n",
       " 'error': '',\n",
       " 'ok': True}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdf3ea4",
   "metadata": {},
   "source": [
    "## Test final make_tooling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91edd371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'testfunc1',\n",
       "  'description': \"Short description of the function.\\n\\nHere is a longer description of the function. It can be multiple lines long and\\ncan contain any information that is relevant to the function.\\n\\nThe function returns: A list of person information, each having a name and city and optional other fields\\n\\nThe return type is: {'type': 'array', 'items': {'type': 'object', 'additionalProperties': {'type': 'string'}}}\",\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'parm1': {'type': 'string',\n",
       "     'description': 'the first parameter'},\n",
       "    'parm2': {'type': 'object',\n",
       "     'additionalProperties': {'type': 'array', 'items': {'type': 'integer'}},\n",
       "     'description': 'the second parameter'},\n",
       "    'parm3': {'type': 'string',\n",
       "     'description': 'the third parameter',\n",
       "     'default': True},\n",
       "    'parm4': {'type': 'array!',\n",
       "     'items': {'type': 'object',\n",
       "      'properties': {'name': {'type': 'string'}, 'city': {'type': 'string'}}},\n",
       "     'description': 'the fourth parameter',\n",
       "     'default': None}},\n",
       "   'required': ['parm1', 'parm2']}}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llms.make_tooling(testfunc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b61f1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'query_names',\n",
       "  'description': 'Query the customer database and return a list of matching names. \\n\\nThis function queries the customer database using the conditions in the where clause and returns\\na list of matching customers. The where clause may use the DB fields \"city\", \"company_name\",\\n\"country\" and \"since_date\" to limit the returned customer list. The where clause can also \\nbe followed by a limit clause to limit the number of returned names.\\n\\nThe function returns: a list of matching customer names\\n\\nThe return type is: {\\'type\\': \\'array\\', \\'items\\': {\\'type\\': \\'string\\'}}',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'where_clause': {'type': 'string',\n",
       "     'description': 'the string containing the where and optionally limit clauses in SQL query format'}},\n",
       "   'required': ['where_clause']}}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llms.make_tooling(query_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeec211c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms_wrapper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
