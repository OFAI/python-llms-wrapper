{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "744579c6-ec0c-4c73-bb38-5c99a566056f",
   "metadata": {},
   "source": [
    "# test-api.ipynb\n",
    "\n",
    "Test API and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6da6e33-e3dd-45d3-abad-ad48a617b1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from typing import Optional, List, Dict\n",
    "sys.path.append(os.path.join(\"..\"))\n",
    "import hjson\n",
    "import docstring_parser\n",
    "import inspect\n",
    "from llms_wrapper.llms import LLMS\n",
    "from llms_wrapper.config import update_llm_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7401b8b9-af81-4a1e-9bfa-bef00ec3ea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    llms=[\n",
    "        # OpenAI\n",
    "        # https://platform.openai.com/docs/models\n",
    "        dict(llm=\"openai/gpt-4o\"),\n",
    "        dict(llm=\"openai/gpt-4o-mini\"),\n",
    "        # dict(llm=\"openai/o1\"),        # restricted\n",
    "        # dict(llm=\"openai/o1-mini\"),   # restricted\n",
    "        # Google Gemini\n",
    "        # https://ai.google.dev/gemini-api/docs/models/gemini\n",
    "        dict(llm=\"gemini/gemini-2.0-flash-exp\"),\n",
    "        dict(llm=\"gemini/gemini-1.5-flash\"),\n",
    "        dict(llm=\"gemini/gemini-1.5-pro\"),\n",
    "        # Anthropic\n",
    "        # https://docs.anthropic.com/en/docs/about-claude/models\n",
    "        dict(llm=\"anthropic/claude-3-5-sonnet-20240620\"),\n",
    "        dict(llm=\"anthropic/claude-3-opus-20240229\"),\n",
    "        # Mistral\n",
    "        # https://docs.mistral.ai/getting-started/models/models_overview/\n",
    "        dict(llm=\"mistral/mistral-large-latest\"),\n",
    "        # XAI\n",
    "        # dict(llm=\"xai/grok-2\"),     # not mapped by litellm yet?\n",
    "        dict(llm=\"xai/grok-beta\"),\n",
    "        # Groq\n",
    "        # https://console.groq.com/docs/models\n",
    "        dict(llm=\"groq/llama3-70b-8192\"),\n",
    "        dict(llm=\"groq/llama-3.3-70b-versatile\"),\n",
    "        # Deepseek\n",
    "        # https://api-docs.deepseek.com/quick_start/pricing\n",
    "        dict(llm=\"deepseek/deepseek-chat\"),\n",
    "        dict(\n",
    "            llm=\"gemini/somemodel\",\n",
    "            max_input_tokens=100000,\n",
    "            cost_per_prompt_token=0.0002,\n",
    "            temperature=0,\n",
    "        ), \n",
    "    ],\n",
    "    providers = dict(\n",
    "        openai = dict(api_key_env=\"MY_OPENAI_API_KEY\"),\n",
    "        gemini = dict(api_key_env=\"MY_GEMINI_API_KEY\"),\n",
    "        anthropic = dict(api_key_env=\"MY_ANTHROPIC_API_KEY\"),\n",
    "        mistral = dict(api_key_env=\"MY_MISTRAL_API_KEY\"),\n",
    "        xai = dict(api_key_env=\"MY_XAI_API_KEY\"),    \n",
    "        groq = dict(api_key_env=\"MY_GROQ_API_KEY\"),\n",
    "        deepseek = dict(api_key_env=\"MY_DEEPSEEK_API_KEY\"),\n",
    "    )\n",
    ")\n",
    "_ = update_llm_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "078083b6-dcf4-4d7e-9950-36ffb058732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llms = LLMS(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a2eb12c-7219-49ee-8f47-e3e87b719795",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['openai/gpt-4o',\n",
       " 'openai/gpt-4o-mini',\n",
       " 'gemini/gemini-2.0-flash-exp',\n",
       " 'gemini/gemini-1.5-flash',\n",
       " 'gemini/gemini-1.5-pro',\n",
       " 'anthropic/claude-3-5-sonnet-20240620',\n",
       " 'anthropic/claude-3-opus-20240229',\n",
       " 'mistral/mistral-large-latest',\n",
       " 'xai/grok-beta',\n",
       " 'groq/llama3-70b-8192',\n",
       " 'groq/llama-3.3-70b-versatile',\n",
       " 'deepseek/deepseek-chat',\n",
       " 'gemini/somemodel']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llms.list_aliases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f000f97f-a6ae-474c-bf3b-61e3dc5d372b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mllms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mknown_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work-git/python-llms-wrapper/llms_wrapper/llms.py:87\u001b[0m, in \u001b[0;36mLLMS.known_models\u001b[0;34m(self, provider)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mknown_models\u001b[39m(\u001b[38;5;28mself\u001b[39m, provider\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m     84\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    Get a list of known models.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work-git/python-llms-wrapper/llms_wrapper/model_list.py:67\u001b[0m, in \u001b[0;36mmodel_list\u001b[0;34m(provider, api_key)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m alist:\n\u001b[1;32m     66\u001b[0m     tmp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(litellm, a)\n\u001b[0;32m---> 67\u001b[0m     tmp \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43ma\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mm\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtmp\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     68\u001b[0m     ret \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tmp\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[0;31mTypeError\u001b[0m: 'bool' object is not iterable"
     ]
    }
   ],
   "source": [
    "llms.known_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5026a5a-28d8-4790-991f-6ba1e21d1b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1e-05, 2.5e-06)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llms.cost_per_token(\"openai/gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50489a92-0520-4ae9-ad74-7c5f27c6c25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llms.max_input_tokens(\"openai/gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6011eb7-ffbe-404f-97d2-31430ed0fb31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llms.max_output_tokens(\"openai/gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b7cd6bb-8bfb-422b-a534-c4573e045601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'llm': 'gemini/somemodel',\n",
       " 'max_input_tokens': 100000,\n",
       " 'cost_per_prompt_token': 0.0002,\n",
       " 'temperature': 0,\n",
       " 'api_key_env': 'MY_GEMINI_API_KEY',\n",
       " 'alias': 'gemini/somemodel',\n",
       " '_cost': 0,\n",
       " '_elapsed_time': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llms[\"gemini/somemodel\"].config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e5714ff-6849-4e26-9bdd-d8201a89e6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3e-07, 7.5e-08)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llms.cost_per_token(\"gemini/gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99c6e1a2-5fb8-45d0-ac59-8f8639dca7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0002, None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llms.cost_per_token(\"gemini/somemodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9607b8e0-89a1-4238-9fd7-05678fb3b85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llms.max_input_tokens(\"gemini/somemodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92f28e32-89f8-4a1e-bea5-7d52917383d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "llms.max_output_tokens(\"gemini/somemodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ae2ffc1-96d0-4e24-a6c7-08a0e1a22893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'What is a monoid?', 'role': 'user'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg1 = llms.make_messages(\"What is a monoid?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7439591a-2b20-4775-8997-d2c975129a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg2 = llms.make_messages(\"What is a monoid? Return a JSON dict that has the single key 'answer' that contains your answer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35eaced1-5c4c-4afc-b7c8-b28d6e33b059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elapsed_time': 4.468285083770752,\n",
       " 'answer': '{\"answer\": \"A monoid is an algebraic structure with a single associative binary operation and an identity element. Formally, a set M is a monoid if it is equipped with a binary operation \\\\\\\\(\\\\\\\\ast: M \\\\\\\\times M \\\\\\\\to M\\\\\\\\) such that: \\\\n1. Associativity: For all a, b, c in M, \\\\\\\\((a \\\\\\\\ast b) \\\\\\\\ast c = a \\\\\\\\ast (b \\\\\\\\ast c)\\\\\\\\).\\\\n2. Identity element: There exists an element e in M such that for all elements a in M, \\\\\\\\(e \\\\\\\\ast a = a \\\\\\\\ast e = a\\\\\\\\). \\\\nMonoids are foundational structures in abstract algebra and have applications in computer science and other fields.\"}',\n",
       " 'error': '',\n",
       " 'ok': True}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llms.query(llmalias=\"openai/gpt-4o\", messages=msg2, response_format=dict(type=\"json_object\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c7f6986-347b-4e50-94bb-31272e798130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func1(a: str, b: int, c: int = 1, d: Optional[List[Dict]] = None) -> str: \n",
    "    \"\"\"\n",
    "    This is the short description.\n",
    "\n",
    "    Here we may have a longer description. This one can go over many lines\n",
    "\n",
    "    :param str a: this is parameter a\n",
    "    :param b: this is parameter b\n",
    "    :type b: int\n",
    "    :param c: some parameter c    \n",
    "    :param d: some parameter d\n",
    "    :return: what it returns\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    return \"x\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b49ca6c6-e5ef-4a92-81b2-307c4c01143a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'func1',\n",
       "   'description': 'Here we may have a longer description. This one can go over many lines',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'a': {'type': 'str', 'description': 'this is parameter a'},\n",
       "     'b': {'type': 'int', 'description': 'this is parameter b'},\n",
       "     'c': {'type': 'int', 'description': 'some parameter c'},\n",
       "     'd': {'type': 'Optional', 'description': 'some parameter d'}},\n",
       "    'required': ['a', 'b']}}}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llms.make_tooling(func1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fe7a25-4431-4a57-b1ee-5d58e7e7b55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = docstring_parser.parse(func1.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9ecf31-7466-487a-be9e-b8c2ac6ee6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14a9676-9521-4917-8bd0-85b15098161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doc.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc453f9-dee7-4521-9e6a-77dcfe05c4aa",
   "metadata": {},
   "source": [
    "## Test Retries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c507ee5-3501-48e6-b4e5-754e0b94b613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'llms': [{'llm': 'ollama/llama3',\n",
       "   'api_url': 'http://localhost:11434',\n",
       "   'num_retries': 3}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config2 = dict(\n",
    "    llms = [\n",
    "        dict(llm=\"ollama/llama3\", api_url=\"http://localhost:11434\", num_retries=3)\n",
    "    ]\n",
    ")\n",
    "config2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cabe5a3-e7b2-40d8-899e-e0c323e5961b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”­ OpenTelemetry Tracing Details ðŸ”­\n",
      "|  Phoenix Project: llms_wrapper_test\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: http://0.0.0.0:6006/v1/traces\n",
      "|  Transport: HTTP + protobuf\n",
      "|  Transport Headers: {}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'llm': 'ollama/llama3',\n",
       " 'api_url': 'http://localhost:11434',\n",
       " 'num_retries': 3,\n",
       " '_cost': 0,\n",
       " '_elapsed_time': 0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llms2 = LLMS(config2, use_phoenix=(\"http://0.0.0.0:6006/v1/traces\", \"llms_wrapper_test\"))\n",
    "# llms2 = LLMS(config2)\n",
    "llms2[\"ollama/llama3\"].config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0daa9377-6c0a-406a-a6be-c4403cf427fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = llms2.make_messages(query=\"What is a monoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04f97697-039d-49de-a0ab-e0739b9b24dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elapsed_time': 7.766540288925171,\n",
       " 'answer': 'A fundamental question!\\n\\nIn abstract algebra, a monoid is an algebraic structure consisting of:\\n\\n1. A set M (the underlying set)\\n2. An associative binary operation âˆ˜ (called the multiplication or product) that combines two elements of M to produce another element in M.\\n\\nTo be more specific, a monoid M satisfies the following properties:\\n\\n1. **Associativity**: For all a, b, c âˆˆ M, it holds that (a âˆ˜ b) âˆ˜ c = a âˆ˜ (b âˆ˜ c). This means that the order in which you combine elements doesn\\'t matter.\\n2. **Identity element**: There exists an element e âˆˆ M, called the identity or neutral element, such that for all a âˆˆ M, a âˆ˜ e = e âˆ˜ a = a.\\n\\nIn other words, a monoid is like a set of things with a way to combine them (using the multiplication operation), where:\\n\\n* Combining elements in any order doesn\\'t change the result.\\n* There\\'s a special \"neutral\" element that leaves anything unchanged when combined with it.\\n\\nMonoids are important in many areas of mathematics and computer science, such as group theory, category theory, programming languages, and more. They provide a framework for studying symmetries, patterns, and structures within sets.\\n\\nExamples of monoids include:\\n\\n* The set of natural numbers (0, 1, 2, ...) with the usual addition operation (+).\\n* The set of integers (-âˆž, ..., -1, 0, 1, ... âˆž) with the usual addition operation (+).\\n* The set of all strings (sequences of characters) with the concatenation operation (âˆ§).\\n* The set of Boolean values (true or false) with the logical AND operation (âˆ§).\\n\\nI hope this helps! Do you have any specific questions about monoids or would you like to explore related topics?',\n",
       " 'error': '',\n",
       " 'ok': True}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret = llms2.query(\n",
    "    \"ollama/llama3\", \n",
    "    messages=messages, \n",
    "    # return_cost=True,\n",
    "    debug=True,\n",
    "    num_retries=0,\n",
    ")\n",
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fe619a-1b32-4ab8-8d20-cda433570a02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8dd01a-92bb-4281-a983-a2561facbd77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms_wrapper",
   "language": "python",
   "name": "llms_wrapper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
