{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "744579c6-ec0c-4c73-bb38-5c99a566056f",
   "metadata": {},
   "source": [
    "# test-models.ipynb\n",
    "\n",
    "Just test model usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6da6e33-e3dd-45d3-abad-ad48a617b1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johann/software/miniconda3/envs/llms_wrapper/lib/python3.11/site-packages/pydantic/_internal/_config.py:345: UserWarning: Valid config keys have changed in V2:\n",
      "* 'fields' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from loguru import logger\n",
    "sys.path.append(os.path.join(\"..\"))\n",
    "from llms_wrapper.llms import LLMS\n",
    "from llms_wrapper.config import update_llm_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21260bb0-48f2-4c52-9de9-157cff1185bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.remove()\n",
    "logger.add(sys.stderr, level=\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7401b8b9-af81-4a1e-9bfa-bef00ec3ea68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'llms': [{'llm': 'openai/gpt-4o',\n",
       "   'api_key_env': 'MY_OPENAI_API_KEY',\n",
       "   'alias': 'openai/gpt-4o'},\n",
       "  {'llm': 'openai/gpt-4o-mini',\n",
       "   'api_key_env': 'MY_OPENAI_API_KEY',\n",
       "   'alias': 'openai/gpt-4o-mini'},\n",
       "  {'llm': 'openai/o1',\n",
       "   'api_key_env': 'MY_OPENAI_API_KEY',\n",
       "   'alias': 'openai/o1'},\n",
       "  {'llm': 'openai/o1-mini',\n",
       "   'api_key_env': 'MY_OPENAI_API_KEY',\n",
       "   'alias': 'openai/o1-mini'},\n",
       "  {'llm': 'gemini/gemini-2.0-flash-exp',\n",
       "   'api_key_env': 'MY_GEMINI_API_KEY',\n",
       "   'alias': 'gemini/gemini-2.0-flash-exp'},\n",
       "  {'llm': 'gemini/gemini-1.5-flash',\n",
       "   'api_key_env': 'MY_GEMINI_API_KEY',\n",
       "   'alias': 'gemini/gemini-1.5-flash'},\n",
       "  {'llm': 'gemini/gemini-1.5-pro',\n",
       "   'api_key_env': 'MY_GEMINI_API_KEY',\n",
       "   'alias': 'gemini/gemini-1.5-pro'},\n",
       "  {'llm': 'anthropic/claude-3-5-sonnet-latest',\n",
       "   'api_key_env': 'MY_ANTHROPIC_API_KEY',\n",
       "   'alias': 'anthropic/claude-3-5-sonnet-latest'},\n",
       "  {'llm': 'anthropic/claude-3-opus-20240229',\n",
       "   'api_key_env': 'MY_ANTHROPIC_API_KEY',\n",
       "   'alias': 'anthropic/claude-3-opus-20240229'},\n",
       "  {'llm': 'mistral/mistral-large-latest',\n",
       "   'api_key_env': 'MY_MISTRAL_AIP_KEY',\n",
       "   'alias': 'mistral/mistral-large-latest'},\n",
       "  {'llm': 'xai/grok-2',\n",
       "   'api_key_env': 'MY_XAI_API_KEY',\n",
       "   'alias': 'xai/grok-2'},\n",
       "  {'llm': 'xai/grok-beta',\n",
       "   'api_key_env': 'MY_XAI_API_KEY',\n",
       "   'alias': 'xai/grok-beta'}],\n",
       " 'providers': {'openai': {'api_key_env': 'MY_OPENAI_API_KEY'},\n",
       "  'gemini': {'api_key_env': 'MY_GEMINI_API_KEY'},\n",
       "  'anthropic': {'api_key_env': 'MY_ANTHROPIC_API_KEY'},\n",
       "  'mistral': {'api_key_env': 'MY_MISTRAL_AIP_KEY'},\n",
       "  'xai': {'api_key_env': 'MY_XAI_API_KEY'}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = dict(\n",
    "    llms=[\n",
    "        # OpenAI\n",
    "        # https://platform.openai.com/docs/models\n",
    "        dict(llm=\"openai/gpt-4o\"),\n",
    "        dict(llm=\"openai/gpt-4o-mini\"),\n",
    "        dict(llm=\"openai/o1\"),\n",
    "        dict(llm=\"openai/o1-mini\"),\n",
    "        # Google Gemini\n",
    "        # https://ai.google.dev/gemini-api/docs/models/gemini\n",
    "        dict(llm=\"gemini/gemini-2.0-flash-exp\"),\n",
    "        dict(llm=\"gemini/gemini-1.5-flash\"),\n",
    "        dict(llm=\"gemini/gemini-1.5-pro\"),\n",
    "        # Anthropic\n",
    "        # https://docs.anthropic.com/en/docs/about-claude/models\n",
    "        dict(llm=\"anthropic/claude-3-5-sonnet-latest\"),\n",
    "        dict(llm=\"anthropic/claude-3-opus-20240229\"),\n",
    "        # Mistral\n",
    "        # https://docs.mistral.ai/getting-started/models/models_overview/\n",
    "        dict(llm=\"mistral/mistral-large-latest\"),\n",
    "        # XAI\n",
    "        dict(llm=\"xai/grok-2\"),\n",
    "        dict(llm=\"xai/grok-beta\"),\n",
    "    ],\n",
    "    providers = dict(\n",
    "        openai = dict(api_key_env=\"MY_OPENAI_API_KEY\"),\n",
    "        gemini = dict(api_key_env=\"MY_GEMINI_API_KEY\"),\n",
    "        anthropic = dict(api_key_env=\"MY_ANTHROPIC_API_KEY\"),\n",
    "        mistral = dict(api_key_env=\"MY_MISTRAL_AIP_KEY\"),\n",
    "        xai = dict(api_key_env=\"MY_XAI_API_KEY\"),    \n",
    "    )\n",
    ")\n",
    "update_llm_config(config)\n",
    "llms = LLMS(config)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a2eb12c-7219-49ee-8f47-e3e87b719795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['openai/gpt-4o',\n",
       " 'openai/gpt-4o-mini',\n",
       " 'openai/o1',\n",
       " 'openai/o1-mini',\n",
       " 'gemini/gemini-2.0-flash-exp',\n",
       " 'gemini/gemini-1.5-flash',\n",
       " 'gemini/gemini-1.5-pro',\n",
       " 'anthropic/claude-3-5-sonnet-latest',\n",
       " 'anthropic/claude-3-opus-20240229',\n",
       " 'mistral/mistral-large-latest',\n",
       " 'xai/grok-2',\n",
       " 'xai/grok-beta']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llms.list_aliases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f8db39d-1e7e-4581-86eb-6f743f0ef2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai/gpt-4o:\n",
      "  Cost per token, input=2.5e-06, output=1e-05\n",
      "  Maximum tokens: 16384\n",
      "openai/gpt-4o-mini:\n",
      "  Cost per token, input=1.5e-07, output=6e-07\n",
      "  Maximum tokens: 16384\n",
      "openai/o1:\n",
      "  Cost per token, input=1.5e-05, output=6e-05\n",
      "  Maximum tokens: 100000\n",
      "openai/o1-mini:\n",
      "  Cost per token, input=3e-06, output=1.2e-05\n",
      "  Maximum tokens: 65536\n",
      "gemini/gemini-2.0-flash-exp:\n",
      "  Cost per token, input=0.0, output=0\n",
      "  Maximum tokens: 8192\n",
      "gemini/gemini-1.5-flash:\n",
      "  Cost per token, input=7.5e-08, output=3e-07\n",
      "  Maximum tokens: 8192\n",
      "gemini/gemini-1.5-pro:\n",
      "  Cost per token, input=3.5e-06, output=1.05e-05\n",
      "  Maximum tokens: 8192\n",
      "anthropic/claude-3-5-sonnet-latest:\n",
      "  No information\n",
      "anthropic/claude-3-opus-20240229:\n",
      "  Cost per token, input=1.5e-05, output=7.5e-05\n",
      "  Maximum tokens: 4096\n",
      "mistral/mistral-large-latest:\n",
      "  Cost per token, input=2e-06, output=6e-06\n",
      "  Maximum tokens: 128000\n",
      "xai/grok-2:\n",
      "  No information\n",
      "xai/grok-beta:\n",
      "  Cost per token, input=5e-06, output=1.5e-05\n",
      "  Maximum tokens: 131072\n"
     ]
    }
   ],
   "source": [
    "for llmalias in llms.list_aliases():\n",
    "    print(f\"{llmalias}:\")\n",
    "    try:\n",
    "        c1, c2 = llms.cost_per_token(llmalias)\n",
    "        print(f\"  Cost per token, input={c1}, output={c2}\")\n",
    "        mt = llms.max_prompt_tokens(llmalias)\n",
    "        print(f\"  Maximum tokens: {mt}\")  \n",
    "    except:\n",
    "        print(f\"  No information\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f50ecff6-28b6-487d-b106-887aaa2c4f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: openai/gpt-4o\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "  ERROR: litellm.BadRequestError: OpenAIException - Error code: 400 - {'error': {'message': 'Unrecognized request argument supplied: cost', 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "Model: openai/gpt-4o-mini\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "  ERROR: litellm.BadRequestError: OpenAIException - Error code: 400 - {'error': {'message': 'Unrecognized request argument supplied: cost', 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "Model: openai/o1\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "  ERROR: litellm.NotFoundError: OpenAIException - Error code: 404 - {'error': {'message': 'The model `o1` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "Model: openai/o1-mini\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "  ERROR: litellm.BadRequestError: OpenAIException - Error code: 400 - {'error': {'message': \"Unknown parameter: 'cost'.\", 'type': 'invalid_request_error', 'param': 'cost', 'code': 'unknown_parameter'}}\n",
      "Model: gemini/gemini-2.0-flash-exp\n",
      "  Answer: Albert\n",
      "\n",
      "Model: gemini/gemini-1.5-flash\n",
      "  Answer: Albert\n",
      "\n",
      "Model: gemini/gemini-1.5-pro\n",
      "  Answer: Albert\n",
      "\n",
      "Model: anthropic/claude-3-5-sonnet-latest\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "  ERROR: litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"cost: Extra inputs are not permitted\"}}\n",
      "Model: anthropic/claude-3-opus-20240229\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "  ERROR: litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"cost: Extra inputs are not permitted\"}}\n",
      "Model: mistral/mistral-large-latest\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "  ERROR: litellm.AuthenticationError: AuthenticationError: MistralException - Error code: 401 - {'message': 'Unauthorized', 'request_id': 'f149a5254a7dbe0902a86b4a4ee1ef10'}\n",
      "Model: xai/grok-2\n",
      "  ERROR: This model isn't mapped yet. model=xai/grok-2-1212, custom_llm_provider=xai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n",
      "Model: xai/grok-beta\n",
      "  Answer: Albert\n"
     ]
    }
   ],
   "source": [
    "messages = llms.make_messages(query=\"What is the first name of the famous physicist who came up with the theory of relativity? Answer with the first name only.\")\n",
    "\n",
    "\n",
    "for llmalias in llms.list_aliases():\n",
    "    print(\"Model:\", llmalias)\n",
    "    cinfo = {}\n",
    "    ret = llms.query(\n",
    "        llmalias, \n",
    "        messages=messages, \n",
    "        return_cost=True,\n",
    "        debug=False,\n",
    "    )\n",
    "    answer = ret[\"answer\"]\n",
    "    error = ret[\"error\"]\n",
    "    if error:\n",
    "        print(\"  ERROR:\", error)\n",
    "    else:\n",
    "        print(\"  Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb08eba-fef2-449e-b9b4-efa69fe1ca4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms_wrapper",
   "language": "python",
   "name": "llms_wrapper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
