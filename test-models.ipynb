{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "744579c6-ec0c-4c73-bb38-5c99a566056f",
   "metadata": {},
   "source": [
    "# test-models.ipynb\n",
    "\n",
    "Just test model usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6da6e33-e3dd-45d3-abad-ad48a617b1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.join(\"..\"))\n",
    "import hjson\n",
    "from llms_wrapper.llms import LLMS\n",
    "from llms_wrapper.config import update_llm_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7401b8b9-af81-4a1e-9bfa-bef00ec3ea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    llms=[\n",
    "        # OpenAI\n",
    "        # https://platform.openai.com/docs/models\n",
    "        dict(llm=\"openai/gpt-4o\"),\n",
    "        dict(llm=\"openai/gpt-4o-mini\"),\n",
    "        # dict(llm=\"openai/o1\"),        # restricted\n",
    "        # dict(llm=\"openai/o1-mini\"),   # restricted\n",
    "        # Google Gemini\n",
    "        # https://ai.google.dev/gemini-api/docs/models/gemini\n",
    "        dict(llm=\"gemini/gemini-2.0-flash-exp\"),\n",
    "        dict(llm=\"gemini/gemini-1.5-flash\"),\n",
    "        dict(llm=\"gemini/gemini-1.5-pro\"),\n",
    "        # Anthropic\n",
    "        # https://docs.anthropic.com/en/docs/about-claude/models\n",
    "        dict(llm=\"anthropic/claude-3-5-sonnet-20240620\"),\n",
    "        dict(llm=\"anthropic/claude-3-opus-20240229\"),\n",
    "        # Mistral\n",
    "        # https://docs.mistral.ai/getting-started/models/models_overview/\n",
    "        dict(llm=\"mistral/mistral-large-latest\"),\n",
    "        # XAI\n",
    "        # dict(llm=\"xai/grok-2\"),     # not mapped by litellm yet?\n",
    "        dict(llm=\"xai/grok-beta\"),\n",
    "        # Groq\n",
    "        # https://console.groq.com/docs/models\n",
    "        dict(llm=\"groq/llama3-70b-8192\"),\n",
    "        dict(llm=\"groq/llama-3.3-70b-versatile\"),\n",
    "        # Deepseek\n",
    "        # https://api-docs.deepseek.com/quick_start/pricing\n",
    "        dict(llm=\"deepseek/deepseek-chat\"),\n",
    "    ],\n",
    "    providers = dict(\n",
    "        openai = dict(api_key_env=\"MY_OPENAI_API_KEY\"),\n",
    "        gemini = dict(api_key_env=\"MY_GEMINI_API_KEY\"),\n",
    "        anthropic = dict(api_key_env=\"MY_ANTHROPIC_API_KEY\"),\n",
    "        mistral = dict(api_key_env=\"MY_MISTRAL_API_KEY\"),\n",
    "        xai = dict(api_key_env=\"MY_XAI_API_KEY\"),    \n",
    "        groq = dict(api_key_env=\"MY_GROQ_API_KEY\"),\n",
    "        deepseek = dict(api_key_env=\"MY_DEEPSEEK_API_KEY\"),\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e185a4ef-091c-47cf-ac7f-a37daa53aa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"example-config2.hjson\", \"wt\") as outfp:\n",
    "    hjson.dump(config, outfp, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "317aade8-1261-4278-b565-0c68379c2667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempting to instrument while already instrumented\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”­ OpenTelemetry Tracing Details ðŸ”­\n",
      "|  Phoenix Project: llms_wrapper_test\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: http://0.0.0.0:6006/v1/traces\n",
      "|  Transport: HTTP + protobuf\n",
      "|  Transport Headers: {}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'llms': [{'llm': 'openai/gpt-4o',\n",
       "   'api_key_env': 'MY_OPENAI_API_KEY',\n",
       "   'alias': 'openai/gpt-4o'},\n",
       "  {'llm': 'openai/gpt-4o-mini',\n",
       "   'api_key_env': 'MY_OPENAI_API_KEY',\n",
       "   'alias': 'openai/gpt-4o-mini'},\n",
       "  {'llm': 'gemini/gemini-2.0-flash-exp',\n",
       "   'api_key_env': 'MY_GEMINI_API_KEY',\n",
       "   'alias': 'gemini/gemini-2.0-flash-exp'},\n",
       "  {'llm': 'gemini/gemini-1.5-flash',\n",
       "   'api_key_env': 'MY_GEMINI_API_KEY',\n",
       "   'alias': 'gemini/gemini-1.5-flash'},\n",
       "  {'llm': 'gemini/gemini-1.5-pro',\n",
       "   'api_key_env': 'MY_GEMINI_API_KEY',\n",
       "   'alias': 'gemini/gemini-1.5-pro'},\n",
       "  {'llm': 'anthropic/claude-3-5-sonnet-20240620',\n",
       "   'api_key_env': 'MY_ANTHROPIC_API_KEY',\n",
       "   'alias': 'anthropic/claude-3-5-sonnet-20240620'},\n",
       "  {'llm': 'anthropic/claude-3-opus-20240229',\n",
       "   'api_key_env': 'MY_ANTHROPIC_API_KEY',\n",
       "   'alias': 'anthropic/claude-3-opus-20240229'},\n",
       "  {'llm': 'mistral/mistral-large-latest',\n",
       "   'api_key_env': 'MY_MISTRAL_API_KEY',\n",
       "   'alias': 'mistral/mistral-large-latest'},\n",
       "  {'llm': 'xai/grok-beta',\n",
       "   'api_key_env': 'MY_XAI_API_KEY',\n",
       "   'alias': 'xai/grok-beta'},\n",
       "  {'llm': 'groq/llama3-70b-8192',\n",
       "   'api_key_env': 'MY_GROQ_API_KEY',\n",
       "   'alias': 'groq/llama3-70b-8192'},\n",
       "  {'llm': 'groq/llama-3.3-70b-versatile',\n",
       "   'api_key_env': 'MY_GROQ_API_KEY',\n",
       "   'alias': 'groq/llama-3.3-70b-versatile'},\n",
       "  {'llm': 'deepseek/deepseek-chat',\n",
       "   'api_key_env': 'MY_DEEPSEEK_API_KEY',\n",
       "   'alias': 'deepseek/deepseek-chat'}],\n",
       " 'providers': {'openai': {'api_key_env': 'MY_OPENAI_API_KEY'},\n",
       "  'gemini': {'api_key_env': 'MY_GEMINI_API_KEY'},\n",
       "  'anthropic': {'api_key_env': 'MY_ANTHROPIC_API_KEY'},\n",
       "  'mistral': {'api_key_env': 'MY_MISTRAL_API_KEY'},\n",
       "  'xai': {'api_key_env': 'MY_XAI_API_KEY'},\n",
       "  'groq': {'api_key_env': 'MY_GROQ_API_KEY'},\n",
       "  'deepseek': {'api_key_env': 'MY_DEEPSEEK_API_KEY'}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_llm_config(config)\n",
    "llms = LLMS(config, use_phoenix=(\"http://0.0.0.0:6006/v1/traces\", \"llms_wrapper_test\"))\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a2eb12c-7219-49ee-8f47-e3e87b719795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['openai/gpt-4o',\n",
       " 'openai/gpt-4o-mini',\n",
       " 'gemini/gemini-2.0-flash-exp',\n",
       " 'gemini/gemini-1.5-flash',\n",
       " 'gemini/gemini-1.5-pro',\n",
       " 'anthropic/claude-3-5-sonnet-20240620',\n",
       " 'anthropic/claude-3-opus-20240229',\n",
       " 'mistral/mistral-large-latest',\n",
       " 'xai/grok-beta',\n",
       " 'groq/llama3-70b-8192',\n",
       " 'groq/llama-3.3-70b-versatile',\n",
       " 'deepseek/deepseek-chat']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llms.list_aliases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f8db39d-1e7e-4581-86eb-6f743f0ef2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai/gpt-4o:\n",
      "  Cost per token, input=1e-05, output=2.5e-06\n",
      "  No information\n",
      "openai/gpt-4o-mini:\n",
      "  Cost per token, input=6e-07, output=1.5e-07\n",
      "  No information\n",
      "gemini/gemini-2.0-flash-exp:\n",
      "  Cost per token, input=0, output=0.0\n",
      "  No information\n",
      "gemini/gemini-1.5-flash:\n",
      "  Cost per token, input=3e-07, output=7.5e-08\n",
      "  No information\n",
      "gemini/gemini-1.5-pro:\n",
      "  Cost per token, input=1.05e-05, output=3.5e-06\n",
      "  No information\n",
      "anthropic/claude-3-5-sonnet-20240620:\n",
      "  Cost per token, input=1.5e-05, output=3e-06\n",
      "  No information\n",
      "anthropic/claude-3-opus-20240229:\n",
      "  Cost per token, input=7.5e-05, output=1.5e-05\n",
      "  No information\n",
      "mistral/mistral-large-latest:\n",
      "  Cost per token, input=6e-06, output=2e-06\n",
      "  No information\n",
      "xai/grok-beta:\n",
      "  Cost per token, input=1.5e-05, output=5e-06\n",
      "  No information\n",
      "groq/llama3-70b-8192:\n",
      "  Cost per token, input=7.9e-07, output=5.9e-07\n",
      "  No information\n",
      "groq/llama-3.3-70b-versatile:\n",
      "  Cost per token, input=7.9e-07, output=5.9e-07\n",
      "  No information\n",
      "deepseek/deepseek-chat:\n",
      "  Cost per token, input=1.1e-06, output=2.7e-07\n",
      "  No information\n"
     ]
    }
   ],
   "source": [
    "for llmalias in llms.list_aliases():\n",
    "    print(f\"{llmalias}:\")\n",
    "    try:\n",
    "        c1, c2 = llms.cost_per_token(llmalias)\n",
    "        print(f\"  Cost per token, input={c1}, output={c2}\")\n",
    "        mt = llms.max_prompt_tokens(llmalias)\n",
    "        print(f\"  Maximum tokens: {mt}\")  \n",
    "    except:\n",
    "        print(f\"  No information\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ddcc241-5c1f-43a3-a870-6ef42c554ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = llms.make_messages(query=\"What is the first name of the famous physicist who came up with the theory of relativity? Answer with the first name only.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f50ecff6-28b6-487d-b106-887aaa2c4f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: openai/gpt-4o\n",
      "  Answer: Albert\n",
      "Model: openai/gpt-4o-mini\n",
      "  Answer: Albert\n",
      "Model: gemini/gemini-2.0-flash-exp\n",
      "  Answer: Albert\n",
      "\n",
      "Model: gemini/gemini-1.5-flash\n",
      "  Answer: Albert\n",
      "\n",
      "Model: gemini/gemini-1.5-pro\n",
      "  Answer: Albert\n",
      "\n",
      "Model: anthropic/claude-3-5-sonnet-20240620\n",
      "  Answer: Albert\n",
      "Model: anthropic/claude-3-opus-20240229\n",
      "  Answer: Albert\n",
      "Model: mistral/mistral-large-latest\n",
      "  Answer: Albert\n",
      "Model: xai/grok-beta\n",
      "  Answer: Albert\n",
      "Model: groq/llama3-70b-8192\n",
      "  Answer: Albert\n",
      "Model: groq/llama-3.3-70b-versatile\n",
      "  Answer: Albert\n",
      "Model: deepseek/deepseek-chat\n",
      "  Answer: Albert\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for llmalias in llms.list_aliases():\n",
    "    print(\"Model:\", llmalias)\n",
    "    cinfo = {}\n",
    "    ret = llms.query(\n",
    "        llmalias, \n",
    "        messages=messages, \n",
    "        return_cost=True,\n",
    "        debug=False,\n",
    "    )\n",
    "    answer = ret[\"answer\"]\n",
    "    error = ret[\"error\"]\n",
    "    if error:\n",
    "        print(\"  ERROR:\", error)\n",
    "    else:\n",
    "        print(\"  Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbb08eba-fef2-449e-b9b4-efa69fe1ca4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLM(openai/gpt-4o)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test using the LLM object\n",
    "llm1 = llms[\"openai/gpt-4o\"]\n",
    "llm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4240545-16a6-432a-ba66-c578e34f2c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elapsed_time': 0.7788379192352295,\n",
       " 'cost': 0.000105,\n",
       " 'n_completion_tokens': 2,\n",
       " 'n_prompt_tokens': 34,\n",
       " 'n_total_tokens': 36,\n",
       " 'answer': 'Albert',\n",
       " 'error': '',\n",
       " 'ok': True}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret = llm1.query(messages=messages, \n",
    "        return_cost=True,\n",
    "        debug=False,)\n",
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50489a92-0520-4ae9-ad74-7c5f27c6c25e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms_wrapper",
   "language": "python",
   "name": "llms_wrapper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
